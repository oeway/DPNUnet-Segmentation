<docs lang="markdown">
[TODO: write documentation for this plugin.]
</docs>

<config lang="json">
{
  "name": "DPNUnet",
  "type": "native-python",
  "version": "0.1.14",
  "description": "[TODO: describe this plugin with one sentence.]",
  "tags": ["CPU", "GPU"],
  "ui": "",
  "cover": "",
  "inputs": null,
  "outputs": null,
  "flags": [],
  "icon": "extension",
  "api_version": "0.1.5",
  "env": {
    "CPU": ["conda create -n dsb2018-cpu python=3.6.8"],
    "GPU": ["conda create -n dsb2018-gpu python=3.6.8"]
  },
  "requirements": {"CPU": ["pip: descartes palettable geojson read-roi gputil namedlist",
                           "pip: lightgbm imgaug scipy==1.0.0 pandas",
                           "conda: opencv tqdm",
                           "conda: pytorch=0.4.1 -c pytorch",
                           "pip: torchvision tensorboardX",
                           "repo: https://github.com/oeway/DPNUnet-Segmentation"],
                    "GPU": ["pip: descartes palettable geojson read-roi gputil namedlist",
                           "pip: lightgbm imgaug scipy==1.0.0 pandas",
                           "conda: opencv tqdm",
                           "conda: pytorch=0.4.1 cuda90 -c pytorch",
                           "pip: torchvision tensorboardX",
                           "repo: https://github.com/oeway/DPNUnet-Segmentation"]
                   },
  "dependencies": ["oeway/ImJoy-Plugins:Im2Im-Dashboard",
                   "https://raw.githubusercontent.com/oeway/DPNUnet-Segmentation/master/DPNUnet-docs.imjoy.html",
                   "https://gist.githubusercontent.com/oeway/9f3866424835d94f05f857178e21603d/raw/ImageAnnotator.imjoy.html",
                   "https://gist.githubusercontent.com/oeway/961c8d7abe24383d3ad6312669fe1d7c/raw/launchpad.imjoy.html"]
}
</config>

<script lang="python">
from imjoy import api
import os
if os.path.exists('/imjoy/imjoy-paper/data-science-bowl/DPNUnet-segmentation-imjoy/src'):
    os.chdir('/imjoy/imjoy-paper/data-science-bowl/DPNUnet-segmentation-imjoy/src')
else:
    os.chdir('DPNUnet-Segmentation/src')

if api.TAG == 'GPU':
    import GPUtil
    # Get the first available GPU
    DEVICE_ID_LIST = GPUtil.getFirstAvailable()
    # Set CUDA_DEVICE_ORDER so the IDs assigned by CUDA match those from nvidia-smi
    os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
    api.log(f'Available GPUs: {DEVICE_ID_LIST}')
    if len(DEVICE_ID_LIST)<= 0:
        api.alert('No GPU available')
        raise Exception('No GPU available')
    DEVICE_ID = DEVICE_ID_LIST[0] # grab first element from list
    api.log(f'Set GPU id to : {DEVICE_ID}')
    # Set CUDA_VISIBLE_DEVICES to mask out all other GPUs than the first available device id
    os.environ["CUDA_VISIBLE_DEVICES"] = str(DEVICE_ID)
else:
    api.log('Using CPU mode.')
    api.alert('WARNING: you are running the plugin in CPU mode, training will be slow.')

import asyncio
from geojson_utils import masks_to_annotation, gen_mask_from_geojson
from postprocessing import wsh
import torch
import os
import numpy as np
import random

from utils import get_csv_folds, update_config, get_folds, cleanup_mac_hidden_files
from config import Config
from dataset.reading_image_provider import ReadingImageProvider, CachingImageProvider, InFolderImageProvider
from dataset.image_types import SigmoidBorderImageType, BorderImageType, PaddedImageType, PaddedSigmoidImageType
from pytorch_utils.concrete_eval import FullImageEvaluator
from pytorch_utils.eval import read_model, predict_batch
from pytorch_utils.callbacks import Callback
from augmentations.transforms import aug_victor
from pytorch_utils.train import train
from merge_preds import merge_files
import json
import cv2
from scipy.misc import imread
import json
import argparse

if os.path.exists('/imjoy/imjoy-paper'):
    ROOT_DIR = '/imjoy/imjoy-paper'
else:
    ROOT_DIR = ''


loop = asyncio.get_event_loop()

class UpdateUI(Callback):
    def __init__(self, total_epoch, dash):
        self.total_epoch = total_epoch
        self.epoch = 0
        self.logs = {}
        self.dash = dash
        self.step = 0

    def on_batch_end(self, batch):
        if batch % 10 == 0:
            logs = self.metrics_collection.train_metrics
            self.logs = logs
            api.showStatus('training epoch:'+str(self.epoch)+'/'+str(self.total_epoch))
            api.log('batch:'+str(batch) + ' '+ str(logs))
            if 'loss' in logs:
                self.dash.updateCallback('onStep', self.step, {'loss': float(str(logs['loss']))})
        self.step += 1

    def on_epoch_end(self, epoch):
        self.epoch = epoch
        logs = self.metrics_collection.val_metrics
        self.logs = logs
        if 'loss' in logs:
            self.dash.updateCallback('onStep', self.step, {'val_loss':  float(str(logs['loss']))})
        api.showProgress(self.epoch/self.total_epoch*100)
        api.showStatus('training epoch:'+str(self.epoch)+'/'+str(self.total_epoch))
        api.log('epoch:'+str(self.epoch)+'/'+str(self.total_epoch) + ' '+ str(logs))
        # plot_tensors(self.dash, tensor_list, label, titles)

def save_config(config, config_path):
    d = {}
    for k in config._fields:
        v = getattr(config, k)
        d[k] = v
    with open(config_path, "w") as write_file:
        json.dump(d, write_file)

def load_config(config_path):
    with open(config_path, 'r') as f:
        cfg = json.load(f)
       
    config = Config(**cfg)
    return config

def get_path_mapping(config, training=True):
    config.dataset_path = config.dataset_path + ('/train' if training else '/test')
    paths = {
        'masks': '',
        'images': '',
        'labels': '',
    }
    mask_name, mask_ext = os.path.splitext(config.mask_file_name)
    fn_mapping = {
        'masks': lambda name: '{}/{}'.format(name, config.mask_file_name if training else mask_name+'_output'+mask_ext ),
        'images': lambda name: '{}/{}'.format(name, config.image_file_name),
        'labels': lambda name: name
    }
    if training:
        paths = {k: os.path.join(config.dataset_path, p) for k, p in paths.items()}
    else:
        paths = {"images": config.dataset_path}
    return paths, fn_mapping


def train_bowl(dash, config, paths, fn_mapping):
    asyncio.set_event_loop(loop)
    dash.setLoading({'status_text': 'Loading data...', 'loading': True})
    if api.TAG == 'GPU':
        torch.backends.cudnn.benchmark = True
    cleanup_mac_hidden_files(config.dataset_path)
    sample_count = len(os.listdir(config.dataset_path))
    idx = list(range(sample_count))
    random.seed(1)
    random.shuffle(idx)
    split = 0.95
    train_idx, val_idx = idx[:int(split*sample_count)], idx[int(split*sample_count):]
    im_type = BorderImageType if not config.sigmoid else SigmoidBorderImageType
    im_val_type = PaddedImageType if not config.sigmoid else PaddedSigmoidImageType
    ds = CachingImageProvider(im_type, paths, fn_mapping)
    val_ds = CachingImageProvider(im_val_type, paths, fn_mapping)
    fold = 0
    api.showStatus('start training ...')
    dash.setLoading({'status_text': 'Start training...', 'loading': True})
    updateUI = UpdateUI(config.nb_epoch, dash)
    num_workers = 0 if os.name == 'nt' else 4
    save_config(config, os.path.join(config.dataset_path, 'config.json'))
    pretrained_model_path = os.path.join(config.dataset_path, '__model__', config.folder, "fold" + str(fold) + "_checkpoint.pth")
    try:
        train(ds, val_ds, fold, train_idx, val_idx, config, num_workers=num_workers, callbacks=[updateUI], transforms=aug_victor(.97), load_from=pretrained_model_path)
    except Exception as e:
        dash.setLoading({'status_text': 'Training failed with error: ' + str(e), 'loading': False})
        api.error(str(e))
        raise
    finally:
        api.log('training stopped')

def eval_bowl(dash, model_path, config, paths, fn_mapping):
    asyncio.set_event_loop(loop)
    test = True
    cleanup_mac_hidden_files(config.dataset_path)
    sample_count = len(os.listdir(config.dataset_path))
    val_indexes = list(range(sample_count))
    im_val_type = PaddedImageType if not config.sigmoid else PaddedSigmoidImageType
    im_prov_type = InFolderImageProvider if test else ReadingImageProvider
    ds = im_prov_type(im_val_type, paths, fn_mapping)
    num_workers = 0 if os.name == 'nt' else 4
    api.showStatus('start prediction ...')
    dash.setLoading({'status_text': 'Start Prediction...', 'loading': True})
    def step_callback(result_dict):
        dash.setLoading({'status_text': 'Start prediction: ' + result_dict['name'], 'loading': True})
        api.log('result saved to ' + result_dict['save_path'])
    keval = FullImageEvaluator(config, ds, test=test, flips=3, step_callback=step_callback,  num_workers=num_workers, border=0)
    fold = 0
    try:
        prefix = ""
        api.alert(config.dataset_path)
        keval.predict(model_path, val_indexes, prefix)
        merge_files(keval.save_dir)
    except Exception as e:
        dash.setLoading({'status_text': 'Prediction failed with error: ' + str(e), 'loading': False})
        api.error(str(e))
        raise
    finally:
        api.log('prediction stopped')


def postprocessing(test_dir, step_callback):
    im_names = os.listdir(test_dir)
    test_ids = [os.path.splitext(i)[0] for i in im_names]
    total = len(test_ids)
    preds_test = [imread(os.path.join(test_dir, im, 'nuclei_border_mask_output.png'), mode='RGB') for im in im_names]
    for n, id_ in enumerate(test_ids):
        print(os.path.join(test_dir, im_names[n], 'nuclei_border_mask_output_watershed.png'))
        test_img = wsh(preds_test[n][...,2] / 255., 0.3, 1 - preds_test[n][...,1] / 255., preds_test[n][...,2] / 255)
        cv2.imwrite(os.path.join(test_dir, im_names[n], 'nuclei_border_mask_output_watershed.png'), (test_img > 0).astype(np.uint8) * 255)
        if step_callback:
            step_callback({'name': id_, 'step': n, 'total': total})

class ImJoyPlugin():
    def __init__(self):
        self.dialog = None
        self.anno_win = None
    async def run(self, ctx):
        # ret = await api.showFileDialog(root='/imjoy/imjoy-paper/data-science-bowl/dsb2018-dataset-v0.1.1', type="directory")
        # datasets_dir = ret.path
        # print("datasets_dir:", datasets_dir)
        # plugin_data = [
        #         {'name': 'Generate masks', 'description': 'Generate masks from annotations for training.', 'callback': self.generate_masks, 'img': 'https://img.icons8.com/color/96/000000/metamorphose.png'},
        #         {'name': 'Train with data from the engine', 'description': 'Use training data stored on a (local or remote) plugin engine.', 'callback': self.train, 'img': 'https://img.icons8.com/color/96/000000/services.png'},
        #         {'name': 'Predict', 'description': 'Segment nuclei in images.', 'callback': self.predict, 'img': 'https://img.icons8.com/color/96/000000/double-right.png'}
        #      ]
        # self.anno_win = await api.createWindow(name="Annotation for DPNUnet", fullscreen=True, type="ImageAnnotator",
        #                                        data=plugin_data,
        #                                        config={})
        # self.dialog = await api.showDialog(type='launchpad', data= plugin_data)

        self.dialog = await api.showDialog(type='launchpad', data= [
                {'name': 'Annotate images', 'description': 'Start annotation of images.', 'callback': self.start_annotation, 'img': 'https://img.icons8.com/color/96/000000/edit.png'},
                {'name': 'Generate masks', 'description': 'Generate masks from annotations for training.', 'callback': self.generate_masks, 'img': 'https://img.icons8.com/color/96/000000/metamorphose.png'},
                {'name': 'Train with data from the engine', 'description': 'Use training data stored on a (local or remote) plugin engine.', 'callback': self.train, 'img': 'https://img.icons8.com/color/96/000000/services.png'},
                {'name': 'Predict', 'description': 'Segment nuclei in images.', 'callback': self.predict, 'img': 'https://img.icons8.com/color/96/000000/double-right.png'},
                {'name': 'Documentation', 'description': 'Show documentation.', 'callback': self.show_docs, 'img': 'https://img.icons8.com/color/96/000000/help.png'},
             ]
        )

    async def show_docs(self):
        if self.dialog is not None:
            self.dialog.close()
        try:
            await this.win_docs.run({'data': {}})
        except:
            this.win_docs = await api.createWindow({
                    'name': 'Documentation - DPNUnet',
                    'type': 'DPNUnet-Segmentation-docs',
                    'w':30, 'h':20,
                    'data': {}
                    })


    async def predict_one(self):
        predict_batch()

    async def predict(self):
        if self.dialog is not None:
            self.dialog.close()

        # options = await api.showDialog( name="Prediction Configurations", ui= "<br>".join([
        # "Image file name { id: 'image_file_name', type:'string', placeholder: 'nuclei.png'}",
        # "Mask file name { id: 'mask_file_name', type:'string', placeholder: 'nuclei_border_mask.png'}",
        # ]))
        fold = 0
        workdirObj = await api.showFileDialog(title="Please select a folder containing your testing data ( folder with a subfolder called `test`).", root='/imjoy/imjoy-paper/data-science-bowl/dsb2018-dataset-v0.1.1', type= 'directory', engine= api.ENGINE_URL)
        if os.path.exists(os.path.join(workdirObj.path, '__model__')):
            default_model_folder = os.path.join(workdirObj.path, '__model__')
        else:
            default_model_folder = '/imjoy/imjoy-paper/SEGMENTATION-MODELS'

        pathObj = await api.showFileDialog(title="Please select a trained model for prediciton", root= default_model_folder, type="directory")
        model_dir = pathObj.path
        config = load_config(os.path.join(model_dir, 'config.json'))
        model_path = os.path.join(model_dir, 'fold{}_best.pth'.format(fold))
        # config = load_config('configs/imjoy_dpn_softmax_s2.json')
        
        config.dataset_path = workdirObj.path
        config.results_dir = workdirObj.path
        config.batch_size = 16
        config.epoch_size = 24
        paths, fn_mapping  = get_path_mapping(config, training=False)
        api.log('config: '+str(config))
        
        self.dash = await api.createWindow(type="Im2Im-Dashboard", name=" DPN-Unet Segmentation Model", w=25, h=10, data={'display_mode': 'all', 'metrics': ["loss", "val_loss"], 'callbacks': ['onStep']})
        await loop.run_in_executor(None, eval_bowl, self.dash, model_path, config, paths, fn_mapping)


        await api.showStatus('Start post-processing...')
        def callback(result):
            step = result['step']
            total = result['total']
            name = result['name']
            if step %10 == 0:
                api.showProgress(step/total*100)
                api.showStatus(f'Processing {step}/{total}: {name}')

        postprocessing(config.dataset_path, callback)

        await api.showProgress(100)
        api.alert(f'Prediction done, generated masks saved to {config.dataset_path}')


    async def train(self):
        if self.dialog is not None:
            self.dialog.close()
        options = await api.showDialog( name="Training Configurations", ui= "<br>".join([
        "Model Name {id: 'model_name', type: 'string', placeholder: 'dpnunet-model-1'}",
        "Epochs { id: 'epochs', type:'number', placeholder: 10000}",
        "Image file name { id: 'image_file_name', type:'string', placeholder: 'nuclei.png'}",
        "Mask file name { id: 'mask_file_name', type:'string', placeholder: 'nuclei_boarder_mask.png'}",
        ]))

        config = load_config('configs/imjoy_dpn_softmax.json')
        ret = await api.showFileDialog(title="Please select a folder containing the training and testing data as subfolders ‘train’ and ‘test.", root='/imjoy/imjoy-paper/SEGMENTATION-DATA', type= 'directory', engine= api.ENGINE_URL)
        config.dataset_path = ret.path
        config.results_dir = config.dataset_path
        config.nb_epoch = options.epochs
        config.batch_size = 16
        config.epoch_size = 24
        paths, fn_mapping  = get_path_mapping(config, training=True)
        api.log('config: '+str(config))
        self.dash = await api.createWindow(type="Im2Im-Dashboard", name="Training DPN-Unet Segmentation Model", w=25, h=10, data={'display_mode': 'all', 'metrics': ["loss", "val_loss"], 'callbacks': ['onStep']})
        try:
            await loop.run_in_executor(None, train_bowl, self.dash, config, paths, fn_mapping)
        except Exception as e:
            api.error(str(e))
            api.alert('Failed to start training, error: ' + str(e))
        else:
            api.alert(f'Training finished.')

    async def generate_masks(self, datasets_dir=None):
        if self.dialog is not None:
            self.dialog.close()
        if datasets_dir is None:
            ret = await api.showFileDialog(root='/imjoy/imjoy-paper/SEGMENTATION-DATA', type="directory")
            datasets_dir = ret.path
            print("datasets_dir:", datasets_dir)
    
        file_ids = os.listdir(os.path.join(datasets_dir, "train"))
        total = len(file_ids)
        for i, file_id in enumerate(file_ids):
            await api.showProgress(i/total*100)
            await api.showStatus(f'Processing {i}/{total}: {file_id}')
            file_path = os.path.join(datasets_dir, "train", file_id, "annotation.json")
            try:
                gen_mask_from_geojson([file_path], masks_to_create_value=["border_mask"])
            except:
                print("generate mask error:", os.path.join(datasets_dir, "train", file_id))
        await api.showProgress(100)
        await api.alert('Finished, generated masks saved to ' + datasets_dir)

    async def start_train(self, config):
        api.alert('training:'+str(config))
        api.log('dataset' + str(config.dataset))
        api.log('current sample' + str(config.current_sample))

    async def run_prediction(self, config):
        api.alert('prediction:'+str(config))

        api.log('dataset' + str(config.dataset))
        api.log('current sample' + str(config.current_sample))

    async def start_annotation(self):
        if self.dialog is not None:
            self.dialog.close()
        annotator_config = {
            'dataset': {
                "api_version": "0.1.6",
                "root_folder": "./datasets/kaggle_data",
                "name": "kaggle_data",
                "channel_config": {
                    "nuclei": {
                        "filter": "nuclei.",
                        "name": "nuclei"
                    }
                },
                "source": "engine",
                "engine_url": "https://127.0.0.1:2957"
            },
            'actions': [
                {'name': 'Generate Masks', 'callback': self.generate_masks,
                 'tooltip': 'Generate border masks from the annotation'},
                {'name': 'Start Training', 'callback': self.start_train,
                 'tooltip': 'Start training on this dataset.'},
                {'name': 'Run Prediction', 'callback': self.run_prediction,
                 'tooltip': 'Run Prediction on this dataset.'},
            ]
        }

        await api.createWindow(name="Annotation for DPNUnet", fullscreen=True, type="ImageAnnotator",
                               data=annotator_config, config={})

    def setup(self):
        api.log('initialized')
        api.register(name="generate_masks_test", run=self.generate_masks_test, ui="generate_masks_test")
        api.register(name="train_test", run=self.train_test, ui="train_test")
        api.register(name="predict_test", run=self.predict_test, ui="predict_test")

    async def generate_masks_test(self, my=None):
        ret = await api.showFileDialog(root=os.getcwd(), type="directory")
        datasets_dir = ret.path
        print("datasets_dir:", datasets_dir)
        await self.generate_masks(datasets_dir)

    async def train_test(self, my=None):
        await self.train()

    async def predict_test(self, my=None):
        await self.predict()

api.export(ImJoyPlugin())
</script>
